{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eeg import EEG, SET, epoch, ms, np, struct\n",
    "# from src.core import REc\n",
    "from src.data_legacy import band\n",
    "from src.connectivity import preprocess, connectivity_analysis, phaselock, phaselag, spectral_coherence, PEC, cross_correlation, PAC\n",
    "from src.tools import exclude_from_sz_cm \n",
    "from os import makedirs\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=no-self-argument, no-member\n",
    "\n",
    "from inspect import isfunction, ismethod, isgeneratorfunction, isgenerator, isroutine\n",
    "from inspect import isabstract, isclass, ismodule, istraceback, isframe, iscode, isbuiltin\n",
    "from inspect import ismethoddescriptor, isdatadescriptor, isgetsetdescriptor, ismemberdescriptor\n",
    "from inspect import isawaitable, iscoroutinefunction, iscoroutine\n",
    "\n",
    "from collections.abc import Iterable as iterable\n",
    "\n",
    "from pickle import load, dump\n",
    "\n",
    "def isfx(field): return ismethod(field) or isfunction(field)\n",
    "\n",
    "class GhostSet:\n",
    "    \"\"\" enhanced interface (ghost) to retrieve class fields \"\"\"\n",
    "    def _meta(data): return {k:v for k,v in data.__dict__.items() if not isfx(v)}\n",
    "    def _at_last(_, sets): pass\n",
    "    def _set(object, **sets):\n",
    "        ''' use to fast initialize fields | needed to avoid initialization problems at copy by value '''\n",
    "        for field in sets: setattr(object, field, sets[field])\n",
    "        object._at_last(sets)\n",
    "GSet = GhostSet\n",
    "\n",
    "def meta(object):\n",
    "    ''' retrieves clonable object metadata (__dict__) as a copy '''\n",
    "    if isinstance(object, GSet): return object._meta()\n",
    "    return {}\n",
    "\n",
    "class ClonableObjectGhost:\n",
    "    \"\"\" enhanced interface (ghost) for clonable objects \"\"\"\n",
    "    def _by_val(_, depth=-1, _layer=0): pass\n",
    "GCo = ClonableObjectGhost\n",
    "\n",
    "class ClonableObject(GSet, GCo):\n",
    "    \"\"\" base clonable object \"\"\"\n",
    "    def __init__(this, **data): this._set(**data)\n",
    "    def __call__(_, **options): _._set(**options)\n",
    "    def _by_val(_, depth=-1, _layer=0):\n",
    "        copy = type(_)()\n",
    "        copy._set(**_._meta())\n",
    "        if depth<0 or depth>_layer:\n",
    "            for field in copy.__dict__:\n",
    "                if isinstance(copy.__dict__[field], ClonableObjectGhost):\n",
    "                    copy.__dict__[field] = copy.__dict__[field]._by_val(depth,_layer+1)\n",
    "        return copy\n",
    "COb = ClonableObject\n",
    "\n",
    "def copy_by_val(object, depth=-1, _layer=0):\n",
    "    if isinstance(object, GCo): return object._by_val(depth,_layer)\n",
    "    return object\n",
    "copy = by_val = vof = copy_by_val\n",
    "\n",
    "class ComparableGhost:\n",
    "    \"\"\" enhanced interface (ghost) for comparing instances \"\"\"\n",
    "    def _compare(a, b):\n",
    "        if type(a) != type(b): return False\n",
    "        if a.__dict__ == b.__dict__: return True\n",
    "        return False\n",
    "    def __eq__(a, b): return a._compare(b)\n",
    "GEq = ComparableGhost\n",
    "\n",
    "class IterableObjectGhost(GSet):\n",
    "    \"\"\" enhanced interface (ghost) for iterables: exposes __dict__,\n",
    "        therefore Iterable Objects are like lua dictionaries \"\"\"\n",
    "    def __contains__(this, key): return key in this.__dict__\n",
    "    def __iter__(this): return iter(this.__dict__)\n",
    "    def items(my): return my.__dict__.items()\n",
    "    def __getitem__(by, field): return by.__dict__[field]\n",
    "    def __setitem__(by, field, value): by.__dict__[field] = value\n",
    "    def pop(by, field): return by.__dict__.pop(field)\n",
    "GIo = IterableObjectGhost\n",
    "\n",
    "class ReprGhost:\n",
    "    \"\"\" enhanced interface (ghost) for the skeleton method _repr,\n",
    "        see implementation of Struct for a working example;\n",
    "        Record __repr__ override uses _lines_ for max lines display \"\"\"\n",
    "    _lines_ = 31\n",
    "    _chars_ = 13\n",
    "    _msgsz_ = 62\n",
    "    _ellipsis_ = ' ... '\n",
    "    def _repr(my, value):\n",
    "        _type = ''.join(''.join(str(type(value)).split('class ')).split(\"'\"))\n",
    "        _value = '{}'.format(value)\n",
    "        if len(_value)>my._chars_:\n",
    "            show = int(my._chars_/2)\n",
    "            _value = _value[:show]+my._ellipsis_+_value[-show:]\n",
    "        return '{} {}'.format(_type, _value)\n",
    "    def _resize(this, message, at=.7):\n",
    "        if len(message)>this._msgsz_:\n",
    "            start = int(at*this._msgsz_)\n",
    "            end = this._msgsz_-start\n",
    "            return message[:start]+this._ellipsis_+message[-end:]\n",
    "        return message\n",
    "GRe = ReprGhost\n",
    "\n",
    "def set_repr_to(lines): GRe._lines_ = lines\n",
    "\n",
    "class Struct(COb, GEq, GIo, GRe):\n",
    "    \"\"\" structured autoprintable object, behaves like a lua dictionary \"\"\"\n",
    "    def __repr__(_):\n",
    "        return '\\n'.join(['{}:\\t{}'.format(k, _._repr(v)) for k,v in _.items()])\n",
    "struct = Struct\n",
    "\n",
    "class RecordableGhost:\n",
    "    \"\"\" enhanced interface (ghost) for type recording,\n",
    "        see Record for a working example \"\"\"\n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        with open(filename, 'rb') as file: return load(file)\n",
    "    def save(data, filename):\n",
    "        with open(filename, 'wb') as file: dump(data, file)\n",
    "        \n",
    "GRec = RecordableGhost\n",
    "\n",
    "class Record(GSet, GCo, GRec, GEq, GRe):\n",
    "    \"\"\" wrapper for any object or value, auto-inspects and provides load/save type structure \"\"\"\n",
    "    data = None\n",
    "    _check = dict(\n",
    "            isfunction=isfunction, ismethod=ismethod, isgeneratorfunction=isgeneratorfunction, isgenerator=isgenerator, isroutine=isroutine,\n",
    "            isabstract=isabstract, isclass=isclass, ismodule=ismodule, istraceback=istraceback, isframe=isframe, iscode=iscode, isbuiltin=isbuiltin,\n",
    "            ismethoddescriptor=ismethoddescriptor, isdatadescriptor=isdatadescriptor, isgetsetdescriptor=isgetsetdescriptor, ismemberdescriptor=ismemberdescriptor,\n",
    "            isawaitable=isawaitable, iscoroutinefunction=iscoroutinefunction, iscoroutine=iscoroutine\n",
    "                   )\n",
    "    def __init__(this, token, **meta):\n",
    "        this.data = token\n",
    "        this.__dict__.update({k:v(token) for k,v in this._check.items()})\n",
    "        super()._set(**meta)\n",
    "    @property\n",
    "    def type(_): return type(_.data)\n",
    "    def inherits(_, *types): return issubclass(_.type, types)\n",
    "    @property\n",
    "    def isbaseiterable(_): return _.inherits(tuple, list, dict, set) or _.isgenerator or _.isgeneratorfunction\n",
    "    @property\n",
    "    def isiterable(_): return isinstance(_.data, iterable) and _.type is not str\n",
    "    def _clone_iterable(_):\n",
    "        if _.inherits(dict): return _.data.copy()\n",
    "        elif _.isgenerator or _.isgeneratorfunction: return (i for i in list(_.data))\n",
    "        else: return type(_.data)(list(_.data)[:])\n",
    "    def _meta(data): return {k:v for k,v in data.__dict__.items() if k != 'data' and not isfx(v)}\n",
    "    def _by_val(_, depth=-1, layer=0):\n",
    "        data = _.data\n",
    "        if _.isiterable: data = _._clone_iterable()\n",
    "        elif _.inherits(ClonableObjectGhost): data = by_val(data, depth, layer)\n",
    "        return type(_)(data, **meta(_))\n",
    "    def __enter__(self): self._instance = self; return self\n",
    "    def __exit__(self, type, value, traceback): self._instance = None\n",
    "    def __repr__(self):\n",
    "        if not hasattr(self, '_preprint'): return Record(self.data, _preprint='', _lines=Record(Record._lines_)).__repr__()\n",
    "        if self.isbaseiterable:\n",
    "            pre, repr = self._preprint, ''\n",
    "            for n,i in enumerate(self.data):\n",
    "                if self._lines.data == 0: break\n",
    "                else: self._lines.data -= 1\n",
    "                index, item = str(n), i\n",
    "                if self.inherits(dict): index += ' ({})'.format(str(i)); item = self.data[i]\n",
    "                repr += pre+'{}: '.format(index)\n",
    "                next = Record(item, _preprint=pre+'\\t', _lines=self._lines)\n",
    "                if next.isiterable: repr += '\\n'\n",
    "                repr += next.__repr__()\n",
    "                repr += '\\n'\n",
    "            return repr\n",
    "        elif self.inherits(GCo): return Record(self.data._meta(), _preprint=self._preprint, _lines=self._lines).__repr__()\n",
    "        else: return self._repr(self.data)\n",
    "REc = Record\n",
    "\n",
    "class Bisect(list, COb):\n",
    "    \"\"\" bisect implementation using clonable objects \"\"\"\n",
    "    def __init__(set, *items, key=None, reverse=False):\n",
    "        if not key: key = lambda  x:x\n",
    "        super().__init__(sorted(items, reverse=reverse, key=key))\n",
    "    def _bisect(set, item, key, reverse, bottom, top):\n",
    "        def _(check):\n",
    "            if key: return key(check)\n",
    "            return check\n",
    "        at = int((top-bottom)/2)+bottom\n",
    "        if len(set)==0: return (0,-1)\n",
    "        if item==_(set[at]): return (at,0)\n",
    "        bigger = item<_(set[at])\n",
    "        if bigger != reverse:\n",
    "            if at-bottom>0: return set._bisect(item, key, reverse, bottom, at)\n",
    "            return (at,-1)\n",
    "        elif top-at>1: return set._bisect(item, key, reverse, at, top)\n",
    "        return (at,1)\n",
    "    def search(_, item, key=None, reverse=False):\n",
    "        if not key: key = lambda x:x\n",
    "        return _._bisect(item, key, reverse, 0, len(_))\n",
    "    def _by_val(_, depth=-1, _layer=0):\n",
    "        copy = super()._by_val(depth, _layer)\n",
    "        copy += _[:]\n",
    "        return copy\n",
    "BSx = Bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = \"/home/kivi/gdrive/epigame-folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woi = input(\"Time window:\\n 1. Non-seizure (baseline)\\n 2. Pre-seizure (5 min prior to seizure)\\n 3. Pre-seizure (4 min prior to seizure)\\n 4. Pre-seizure (3 min prior to seizure)\\n 5. Pre-seizure (2 min prior to seizure)\\n 6. Pre-seizure (1 min prior to seizure)\\n 7. Transition to seizure (1 min interval)\\n 8. Transition to seizure (2 min interval)\\n 9. Transition to seizure (60% seizure length interval)\\n 10. Seizure\\n Indicate a number: \")\n",
    "\n",
    "method_idx = input(\"Connectivity method:\\n 1. PEC\\n 2. Spectral Coherence\\n 3. Phase Lock Value\\n 4. Phase-Lag Index\\n 5. Cross-correlation\\n 6. Phase-amplitude coupling\\n Indicate a number: \")\n",
    "\n",
    "ext = \"\"\n",
    "if \"2\" == method_idx: \n",
    "    im = input(\"Imaginary part (Y/N): \").upper()\n",
    "    if im == \"Y\": imag,ext = True,\"I\"\n",
    "    elif im == \"N\": imag,ext = False,\"R\"\n",
    "\n",
    "bands, Bands = input(\"Filter the signal: Y/N \").upper(), False\n",
    "\n",
    "if bands==\"N\": bands = \"w\"\n",
    "elif bands==\"Y\": \n",
    "    Bands = True\n",
    "    mn = int(input(\"Set band range min: \"))\n",
    "    mx = int(input(\"Set band range max: \"))\n",
    "    bands = (mn,mx)\n",
    "\n",
    "method_code = {'1':\"PEC\", '2':\"SC_\", '3':\"PLV\", '4':\"PLI\", '5':\"CC\", '6':\"PAC\"}   \n",
    "woi_code = {'1':\"baseline\", '2':\"preseizure5\", '3':\"preseizure4\", '4':\"preseizure3\", '5':\"preseizure2\", '6':\"preseizure1\", '7':\"transition1\", '8':\"transition2\", '9':\"transition60\", '10':\"seizure\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining path to the EDF file. Filename format should be: patientacronym*-baseline.EDF or patientacronym*-seizure.EDF (asterix signifies a regular expression for any string of choice).\n",
    "##### Subject identifier is saved as a three-letter acronym. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_baseline = main_folder + \"data/ASJ2016APR14-PAc-baseline.EDF\"\n",
    "file_seizure = main_folder + \"data/ASJ2016APR14-PAc-seizure.EDF\"\n",
    "\n",
    "subject_id = file_seizure.split(\"/\")[-1][0:3]\n",
    "print(\"Subject ID:\", subject_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connectivity will be measured in epochs of data and later classified between baseline and a window of interest (WOI).\n",
    "##### The WOI is fragmented into epochs of 1 second (span), with half-second overlaps (step). \n",
    "##### To keep the dataset balanced, we considered a fixed number of epochs, irregardless of the WOI duration. This number was fixed to 119 epochs (60/0.5-1), which covers a 1-minute window using the pre-set span and step parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span, step = 1000, 500      # in ms\n",
    "min_woi_duration = 60000    # in ms\n",
    "n_epochs = int((min_woi_duration/step)-1)\n",
    "\n",
    "print(\"Number of epochs to consider for classification =\", n_epochs)\n",
    "\n",
    "eeg_seizure = EEG.from_file(file_seizure, epoch(ms(step), ms(span)))    # load raw seizure SEEG data as an EEG object (class) \n",
    "eeg_baseline = EEG.from_file(file_baseline, epoch(ms(step), ms(span)))   # load raw baseline SEEG data as an EEG object (class) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Consult the clinical annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Seizure file annotations:\\n\\n\", [note for note in eeg_seizure.notes])\n",
    "print(\"\\nBaseline file annotations:\\n\\n\", [note for note in eeg_baseline.notes])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check file duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Seizure file duration:\", eeg_seizure.duration)\n",
    "print(\"Baseline file duration:\", eeg_baseline.duration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: The code below is not redundant, double check for each patient and create a redundant version\n",
    "\n",
    "nodes_seizure = list(eeg_seizure.axes.region)\n",
    "nodes_baseline = list(eeg_baseline.axes.region)\n",
    "\n",
    "nodes=[]\n",
    "missing_node_ids=[]\n",
    "extra_nodes_in = None\n",
    "\n",
    "if nodes_seizure==nodes_baseline: nodes = nodes_seizure\n",
    "else:\n",
    "    if len(nodes_seizure)>len(nodes_baseline): \n",
    "        extra_nodes_in = \"seizure\"\n",
    "        missing_nodes, nodes = [node for node in nodes_seizure if node not in nodes_baseline], nodes_seizure\n",
    "        for missing in missing_nodes: \n",
    "            print(f\"Node {missing} removed from seizure file as not present in baseline file.\")\n",
    "            missing_node_ids.append(nodes.index(missing))\n",
    "            del nodes[nodes.index(missing)]\n",
    "            eeg_seizure.axes.region.remove(missing)\n",
    "    \n",
    "    elif len(nodes_seizure)<len(nodes_baseline): \n",
    "        extra_nodes_in = \"baseline\"\n",
    "        missing_nodes, nodes = [node for node in nodes_baseline if node not in nodes_seizure], nodes_baseline\n",
    "        for missing in missing_nodes: \n",
    "            for missing in missing_nodes: \n",
    "                print(f\"Node {missing} removed from baseline file as not present in seizure file.\")\n",
    "                missing_node_ids.append(nodes.index(missing))\n",
    "                del nodes[nodes.index(missing)]\n",
    "                eeg_baseline.axes.region.remove(missing)\n",
    "\n",
    "print(\"\\nFiles now have the same nodes:\", nodes_seizure==nodes_baseline)\n",
    "print(\"Number of nodes =\", len(nodes))\n",
    "print(nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The raw signal will be resampled to 500 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sampling\n",
    "\n",
    "if eeg_baseline.fs == 50 and eeg_seizure.fs == 50: \n",
    "    \n",
    "    print(\"WARNING: The sampling frequency may have been incorrectly filed... Overwrite with data from subsmeta.xlsx table for now; check with Ale later\")\n",
    "    eeg_seizure._set(fs = 500)\n",
    "    eeg_baseline._set(fs = 500)\n",
    "\n",
    "print(\"Sampling freqency (seizure file) =\", eeg_seizure.fs)\n",
    "print(\"Sampling freqency (baseline file) =\", eeg_baseline.fs)\n",
    "\n",
    "fs_min = min(eeg_seizure.fs, eeg_baseline.fs)\n",
    "\n",
    "# set the resampled frequency to 500 Hz if sampling is not already 512 Hz\n",
    "resampling = 512 if fs_min==512 else 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label the non-seizure (baseline) and seizure epochs relative to the position of clinical annotations (seizure start, seizure end). WOI is always defined relative to the seizure start. The baseline data is labeled independently.\n",
    "##### Baseline file has arbitrary annotations, \"EEG inicio\" in the middle point and \"EEG fin\" at the end. The annotations serve to split the recording into two halves, for computing the baseline connectivity change (change from the first half to the second half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET(eeg_seizure, _as='N')                      # N - baseline (non-seizure)\n",
    "SET(eeg_seizure, 'EEG inicio', 'W')            # W - WOI\n",
    "SET(eeg_seizure, 'EEG fin', 'S', epoch.END)    # S - seizure\n",
    "\n",
    "SET(eeg_baseline, _as='N')\n",
    "SET(eeg_baseline, 'mitad-NS', 'W')            # W - middle point\n",
    "SET(eeg_baseline, 'NS-fin', 'S', epoch.END)    # S - terminal point (end of recording)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimize the positions of epochs relative to the clinical annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_seizure.optimize()\n",
    "eeg_seizure.remap()\n",
    "\n",
    "eeg_baseline.optimize()\n",
    "eeg_baseline.remap()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save seizure duration as the number of epochs present between the clinical annotations of seizure start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = int((eeg_seizure.notes['EEG fin'][0].time - eeg_seizure.notes['EEG inicio'][0].time)*(span/step))\n",
    "print(\"Seizure length =\", units/2, \"s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Introduce a virtual mask into the eeg object, which indicates the time window to which an epoch belongs to (baseline, WOI or seizure). WOI is defined relative to the seizure start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if woi == \"1\":\n",
    "    woi_start = -units\n",
    "    woi_end = 0\n",
    "\n",
    "elif woi in [str(n) for n in [2,3,4,5,6]]:\n",
    "    woi_start = - int(woi_code[woi][-1])*n_epochs\n",
    "    woi_end = - (int(woi_code[woi][-1])-1)*n_epochs\n",
    "\n",
    "elif woi in [str(n) for n in [7,8]]:\n",
    "    woi_start = - int(round(int(woi_code[woi][-1])*60/2))\n",
    "    woi_end = - woi_start\n",
    "\n",
    "elif woi == \"9\":\n",
    "    woi_start = - int(round(units*.3))\n",
    "    woi_end = - woi_start\n",
    "\n",
    "elif woi == \"10\":\n",
    "    woi_start = -1\n",
    "    woi_end = 0\n",
    "\n",
    "eeg_seizure.tag(('W', 'S'), W=range(int(woi_start),int(woi_end),1), S=range(0,-units,-1))\n",
    "\n",
    "eeg_baseline.tag(('W', 'S'), W=range(int(woi_start),int(woi_end),1), S=range(0,-units,-1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fetch the WOI epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, ai = eeg_seizure.sample.get('W', n_epochs)   \n",
    "b, bi = eeg_baseline.sample.get('W', n_epochs)   \n",
    "i = ai + bi                         \n",
    "x = a + b                         \n",
    "y = [1]*n_epochs + [0]*n_epochs\n",
    "\n",
    "print(\"Total number of epochs (seizure + baseline) =\", len(x))\n",
    "print(\"Epoch shape =\", a[0].shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "j = randint(0, n_epochs-1)\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.plot(a[j][0])\n",
    "plt.title(\"Epoch example (seizure file)\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.plot(b[j][0])\n",
    "plt.title(\"Epoch example (baseline file)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_seizure = [preprocess(eeg_seizure, ep, resampling) for i,ep in enumerate(a)] \n",
    "print(\"Resampled to\", pp_seizure[0].shape)\n",
    "\n",
    "pp_baseline = [preprocess(eeg_baseline, ep, resampling) for i,ep in enumerate(b)] \n",
    "print(\"Resampled to\", pp_baseline[0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter in the set frequency band, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpp_seizure = [band(e, bands, pp_seizure[0].shape[1]) for e in pp_seizure] if Bands else pp_seizure\n",
    "fpp_baseline = [band(e, bands, pp_baseline[0].shape[1]) for e in pp_baseline] if Bands else pp_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = struct(x=np.array(x), y=np.array(y), i=np.array(i)) # initiating an object for storing a connecivity matrix with shape (x, y) and epoch indices\n",
    "\n",
    "cm._set(nodes = nodes)\n",
    "\n",
    "epochs = fpp_seizure + fpp_baseline\n",
    "\n",
    "if method_code[method_idx] == \"SC_\":\n",
    "    cm._set(X = connectivity_analysis(epochs, spectral_coherence, fs=resampling, imag=imag))\n",
    "\n",
    "elif method_code[method_idx] == \"PEC\": \n",
    "    parallelize = Parallel(n_jobs=-1)(delayed(PEC)(ep,i+1) for i,ep in enumerate(fpp_seizure))\n",
    "    cm_pec = [p for p in parallelize]\n",
    "    cm._set(X = cm_pec)\n",
    "\n",
    "elif method_code[method_idx] in \"PLV\":\n",
    "    cm._set(X = connectivity_analysis(epochs, phaselock))\n",
    "\n",
    "elif method_code[method_idx] == \"PLI\":\n",
    "    cm._set(X = connectivity_analysis(epochs, phaselag))\n",
    "\n",
    "elif method_code[method_idx] == \"CC\":\n",
    "    cm._set(X = connectivity_analysis(epochs, cross_correlation))\n",
    "\n",
    "elif method_code[method_idx] == \"PAC\":\n",
    "    cm._set(X = connectivity_analysis(epochs, PAC, dtail=True, fs=resampling))\n",
    "\n",
    "if extra_nodes_in is not None:\n",
    "    for m in missing_node_ids:\n",
    "        print(\"Mismatched node index:\", m)\n",
    "        if extra_nodes_in==\"seizure\":\n",
    "            cm.X = exclude_from_sz_cm(cm.X, m)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(cm.X[-1], cmap='Blues', interpolation='nearest')\n",
    "plt.title(\"Connectivity matrix example\")\n",
    "plt.show()\n",
    "print(cm.X[-1])\n",
    "\n",
    "print(\"Seizure CM shape =\", cm.X[0].shape)\n",
    "print(\"Baseline CM shape =\", cm.X[-1].shape)\n",
    "print(\"Number of CMs saved =\", len(cm.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cm = main_folder + \"connectivity_matrices/\"\n",
    "makedirs(path_cm, exist_ok=True)\n",
    "\n",
    "if Bands:          REc(cm).save(path_cm + f\"{subject_id}-{woi_code[woi]}-{method_code[method_idx]}{ext}-{bands}.prep\".replace(\" \",\"\")) \n",
    "elif not Bands:    REc(cm).save(path_cm + f\"{subject_id}-{woi_code[woi]}-{method_code[method_idx]}{ext}.prep\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
