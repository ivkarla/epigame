{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook compares outcomes based on scores obtained using combinations of two connectivity measures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_measures = [\"PAC\",\n",
    "                 \"SCR-(0,4)\",\"SCR-(4,8)\",\"SCR-(8,13)\",\"SCR-(13,30)\",\"SCR-(30,70)\",\"SCR-(70,150)\",\n",
    "                \"SCI-(0,4)\",\"SCI-(4,8)\",\"SCI-(8,13)\",\"SCI-(13,30)\",\"SCI-(30,70)\",\"SCI-(70,150)\",\n",
    "                \"PLV-(0,4)\",\"PLV-(4,8)\",\"PLV-(8,13)\",\"PLV-(13,30)\",\"PLV-(30,70)\",\"PLV-(70,150)\",\n",
    "                \"PLI-(0,4)\", \"PLI-(4,8)\", \"PLI-(8,13)\", \"PLI-(13,30)\", \"PLI-(30,70)\", \"PLI-(70,150)\", \n",
    "                \"CC-(0,4)\",\"CC-(4,8)\",\"CC-(8,13)\",\"CC-(13,30)\",\"CC-(30,70)\",\"CC-(70,150)\"] \n",
    "\n",
    "# The best measures (AUC>0.8)\n",
    "conn_measures = [\"PAC\",\n",
    "\"CC-(8,13)\",\n",
    "\"CC-(70,150)\",\n",
    "\"PLI-(0,4)\",\n",
    "\"SCI-(0,4)\",\n",
    "\"PLI-(70,150)\",\n",
    "\"SCR-(4,8)\",\n",
    "\"CC-(0,4)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pickle import load, dump\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs, threshold):\n",
    "    # function to map all values >=threshold to 1 and all values <threshold to 0\n",
    "\n",
    "\treturn list((pos_probs >= threshold).astype('int')) \n",
    "\n",
    "\n",
    "def moving_thresh_auc(predictive_measure=[], outcome=[], moving_step=0.00001):\n",
    "    # returns AUC, best threshold, true negatives and true positives at the best threshold\n",
    "\n",
    "    thresholds = np.arange(0, np.max(predictive_measure), moving_step)\n",
    "\n",
    "    g = np.array([pm for i,pm in enumerate(predictive_measure) if outcome[i]==\"good\"])\n",
    "    b = np.array([pm for i,pm in enumerate(predictive_measure) if outcome[i]==\"bad\"])\n",
    "\n",
    "    A, A_top = 0, 0\n",
    "    T = 0\n",
    "    tp_top, tn_top = 0, 0\n",
    "    step = 0\n",
    "    for t in thresholds:    \n",
    "        g_l, b_l = to_labels(g, t), to_labels(b, t)\n",
    "        tp = sum(g_l)/14 \n",
    "        tn = b_l.count(0)/7\n",
    "        A = (tp + tn)/2\n",
    "        if A>A_top: \n",
    "            step=0\n",
    "            A_top=A\n",
    "            T=t\n",
    "            tn_top,tp_top=tn,tp\n",
    "        elif A==A_top: step+=moving_step\n",
    "\n",
    "    return (A_top, T, tn_top, tp_top)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code below computes Welch t-test or MannWhitneyU double-sided test with Bonferroni correction, depending on if the scores are distibuted normally or not, respectively.\n",
    "#### Plot only the statistically significant differences.\n",
    "#### Compute AUC using a moving threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# main_folder = \"/content/gdrive/My Drive/epigame-folder/\"\n",
    "\n",
    "woi = \"preseizure1\"\n",
    "\n",
    "main_folder = \"/home/kivi/gdrive/epigame-folder/\"\n",
    "\n",
    "path_res = main_folder + f\"{woi}/\"\n",
    "\n",
    "path_deck = main_folder + \"decks/\"\n",
    "path_scores = main_folder + \"game_scores/\"\n",
    "\n",
    "ext = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many scores to consider in combination?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "from scipy.stats import shapiro, ttest_ind, mannwhitneyu\n",
    "from itertools import combinations\n",
    "\n",
    "# Do not print out pyplot outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\"\n",
    "\n",
    "Sigmas, CM, Strategy, Gauss, Pvalue_Shapiro, Test, Pvalue, MAUC, T, TN, TP = [],[],[],[],[],[],[],[],[],[],[]\n",
    "\n",
    "for sigmas in [2,3,4]:\n",
    "\n",
    "    load_data = pd.read_excel(path_res+f\"surgical_outcome_data_{sigmas}sigma.xlsx\", engine='openpyxl')\n",
    "\n",
    "    strategies = [\"mm\", \"mx\", \"av\", \"rn\"]\n",
    "\n",
    "    load_data[\"Mean_overlap_ratio\"].fillna(0, inplace=True) # if 0 winners, nan is saved, so replace it with 0\n",
    "\n",
    "    for cm in combinations(conn_measures, combination_length): # combinations of scores based on different connectivity measures\n",
    "        cm1,cm2,cm3 = cm[0],cm[1],cm[2]\n",
    "        print(cm1,cm2,cm3)\n",
    "\n",
    "        for strategy in strategies:\n",
    "            data1 = load_data.groupby(\"CM\").get_group(cm1).groupby(\"Strategy\").get_group(strategy)\n",
    "            data2 = load_data.groupby(\"CM\").get_group(cm2).groupby(\"Strategy\").get_group(strategy)\n",
    "            data3 = load_data.groupby(\"CM\").get_group(cm3).groupby(\"Strategy\").get_group(strategy)\n",
    "\n",
    "            # the combination is made as a mean value between two scores\n",
    "            x_plot = [np.mean([val, list(data2.Mean_overlap_ratio)[i], list(data3.Mean_overlap_ratio)[i]]) for i,val in enumerate(data1.Mean_overlap_ratio)]\n",
    "            y_plot = [\"good\" if val==1 else \"bad\" for val in data1[\"Outcome\"]]\n",
    "\n",
    "            data = data1\n",
    "            data.Mean_overlap_ratio = x_plot\n",
    "\n",
    "            # calculate moving threshold-based AUC\n",
    "            mauc = moving_thresh_auc(x_plot, y_plot, moving_step=0.00001)\n",
    "\n",
    "            group1 = [x for i,x in enumerate(x_plot) if y_plot[i]==1]\n",
    "            group0 = [x for i,x in enumerate(x_plot) if y_plot[i]==0]\n",
    "\n",
    "            gaussian, stest = False, ''\n",
    "            stat1, p1 = shapiro(group1)\n",
    "            stat0, p0 = shapiro(group0)\n",
    "\n",
    "            pvalue = 1\n",
    "            if p1 > 0.05 or p0 > 0.05: _, pvalue = mannwhitneyu(group1, group0, alternative='two-sided'); stest = 'Mann-Whitney'; gaussian = True\n",
    "            elif p1 <= 0.05 and p0 <= 0.05: _, pvalue = ttest_ind(group1, group0, equal_var = False); stest = 't-test_welch'\n",
    "\n",
    "            g = sns.catplot(data=data, x='Outcome', y='Mean_overlap_ratio', order=[1,0], kind=\"box\", hue=\"Outcome\",\n",
    "                            palette=[\"#FFA7A0\", \"#ABEAC9\"],\n",
    "                            height=4, aspect=.7);\n",
    "            g.map_dataframe(sns.stripplot, x='Outcome', y='Mean_overlap_ratio', order=[1,0], hue=\"Outcome\",\n",
    "                            palette=[\"#404040\",\"#404040\"],\n",
    "                            alpha=0.6, dodge=True);\n",
    "\n",
    "            p_annot = add_stat_annotation(g.axes[0][0], data=data, x=x_plot, y=y_plot, order=[\"good\",\"bad\"],\n",
    "                            box_pairs=[(\"good\",\"bad\")],\n",
    "                            test=stest, text_format='star', loc='outside', verbose=0);\n",
    "            \n",
    "            pvalue_statannot = p_annot[1][0].__dict__[\"pval\"]\n",
    "            if pvalue<=0.05:\n",
    "                print(\"P-value computed by statannot =\", pvalue_statannot)\n",
    "                print(stest)\n",
    "                plt.title(f\"Sigmas = {sigmas}; Measure = {cm}; Strategy = {strategy}; p-value = {pvalue}; AUC = {mauc[0]}\", pad=50)\n",
    "                plt.show()\n",
    "\n",
    "            plt.close('all')\n",
    "\n",
    "            Sigmas.append(sigmas)\n",
    "            CM.append((cm1,cm2))\n",
    "            Strategy.append(strategy)\n",
    "            Gauss.append(gaussian)\n",
    "            Pvalue_Shapiro.append((p0,p1))\n",
    "            Test.append(stest)\n",
    "            Pvalue.append(pvalue)\n",
    "            MAUC.append(mauc[0])\n",
    "            T.append(mauc[1])\n",
    "            TN.append(mauc[2])\n",
    "            TP.append(mauc[3])\n",
    "\n",
    "outcome_combs = pd.DataFrame({\"CM\":CM, \"Strategy\":Strategy, \"Sigmas\":Sigmas,\n",
    "                                     \"Gauss\":Gauss, \"Pvalue-Shapiro\":Pvalue_Shapiro,\n",
    "                                     \"Test\":Test, \"Pvalue\":Pvalue,\n",
    "                                     \"MAUC\":MAUC, \"T\":T, \"TN\":TN, \"TP\":TP})\n",
    "outcome_combs.to_excel(path_res+f\"surgical_outcome_prediction_combinations.xlsx\")\n",
    "pass;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
